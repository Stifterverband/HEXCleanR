% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/detect_lang_with_openai.R
\name{detect_lang_with_openai}
\alias{detect_lang_with_openai}
\title{Detektiert die Sprache in einer Spalte eines Dataframes mittels OpenAI GPT-API}
\usage{
detect_lang_with_openai(
  df,
  spalte,
  db_data_path,
  export_path = "db_safety_export.rds",
  batch_size = 100
)
}
\arguments{
\item{df}{Ein Dataframe, der die zu klassifizierende Textspalte enthält.}

\item{spalte}{Name der Spalte (String), deren Inhalt analysiert werden soll (z. B. "titel").}

\item{db_data_path}{Pfad zur permanenten RDS-Datenbank mit historischen Klassifikationen.}

\item{export_path}{Pfad zum Sicherheits-Export (RDS), der den aktuellen Fortschritt speichert.
Standard ist "db_safety_export.rds".}

\item{batch_size}{Anzahl der Titel pro API-Abfrage. Standard ist 50.}
}
\value{
Der ursprüngliche Dataframe, ergänzt um die vervollständigte Spalte \code{sprache_recoded}.
}
\description{
Diese Funktion nutzt die OpenAI GPT-API, um die Sprache von Texten (z. B. Titeln) zu erkennen.
Sie arbeitet hocheffizient, indem sie bereits vorhandene Klassifikationen aus einer
Datenbank sowie einem Sicherheits-Export berücksichtigt und nur neue, einzigartige
Texte an die API sendet.
}
\details{
Ablauf der Funktion im Detail:
\enumerate{
\item Vorhandene Datenquellen: Falls vorhanden, werden Sprach-Klassifikationen aus \code{db_data_path}
und \code{export_path} geladen. Bestehende Werte im Dataframe werden NICHT überschrieben,
sondern nur fehlende Werte (NAs) ergänzt (Lookup-Logik).
\item Einzigartigkeit: Es werden nur die eindeutigen (unique) Texte extrahiert, die noch
keinen Wert in \code{sprache_recoded} besitzen, um API-Kosten zu minimieren.
\item Batch-Verarbeitung: Die Texte werden in Batches an das Modell (gpt-4o-mini) gesendet.
\item Validierung & Sicherheit: Die API-Antworten werden strikt gegen eine Liste erlaubter
Sprachen geprüft. Halluzinationen oder Fachbegriffe werden als "Sonstiges" gelabelt.
\item Persistenz: Nach jedem Batch wird der Fortschritt sofort in \code{export_path} gespeichert.
}

Die Funktion nutzt \code{ellmer::parallel_chat} für hohe Geschwindigkeit und setzt die
Modell-Temperatur auf 0, um die Reproduzierbarkeit zu maximieren und "Kreativität"
der KI zu unterbinden.
}
